{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Question and Answering\n",
    "\n",
    "This notebook is about Visual Question and answering. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import csv\n",
    "import string\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helpers.config import *\n",
    "from helpers.preprocessing import *\n",
    "from helpers.utils_v2 import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resetting default tensorflow computational Graph\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights file is :  ../weights/vgg16_weights.npz\n",
      "Config data path is:  ../data/dataset_v7w_telling.json\n",
      "Glove vectors path is:  ../data/glove.6B.50d.txt\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "print (\"Weights file is : \", cfg.weights_path)\n",
    "print (\"Config data path is: \",cfg.data_path)\n",
    "print (\"Glove vectors path is: \",cfg.glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data required for the Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training samples are:  111894\n",
      "Validation examples number:  27974\n"
     ]
    }
   ],
   "source": [
    "samples = loadData(cfg.data_path.split('../')[1])\n",
    "train_samples, val_samples = train_test_split( samples, test_size= 0.2)\n",
    "print (\"Total number of training samples are: \",len(train_samples))\n",
    "print (\"Validation examples number: \",len(val_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading the Glove vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/glove.6B.50d.txt\n"
     ]
    }
   ],
   "source": [
    "## Loading glove vectors here. \n",
    "W2VEC = load_glove(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions available in the utils.py\n",
    "\n",
    "1. Encoding the image\n",
    "2. Encoding the text\n",
    "3. Loading the Weights of the pretrained model\n",
    "4. Loading placeholders\n",
    "5. Variables class\n",
    "6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "1. Load the image, question and answer here and train the network. \n",
    "2. Will get the output data in the shape (N, image, question, answer, groundtruth, option1, option2, option3)\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2VEC_LEN = 50\n",
    "MAX_QUESTION_WORDS = 15\n",
    "MAX_ANSWER_WORDS = 5\n",
    "\n",
    "def vectorize(words_sequence, max_words=15, clean=False):\n",
    "    'Takes a sentence and returns corresponding list of GloVecs'\n",
    "\n",
    "    if clean:\n",
    "        sent = _dataCleaning(words_sequence)\n",
    "\n",
    "    words = words_sequence.lower().translate(string.punctuation).strip().split()\n",
    "    # ignoring words beyond max_words\n",
    "    words = words[:max_words]\n",
    "    words2vec = np.empty((1, W2VEC_LEN))\n",
    "\n",
    "    for w in words:\n",
    "        word2vec = W2VEC.get(w.lower())\n",
    "\n",
    "        if word2vec is None:\n",
    "            word2vec = np.random.rand(W2VEC_LEN)\n",
    "\n",
    "        word2vec = word2vec.reshape((1, W2VEC_LEN))\n",
    "        words2vec = np.concatenate((words2vec, word2vec), axis=0)\n",
    "\n",
    "    PADDING = np.zeros((1, W2VEC_LEN))\n",
    "\n",
    "    for _ in np.arange(max_words - len(words)):\n",
    "        words2vec = np.concatenate((words2vec, PADDING), axis=0)\n",
    "\n",
    "    return words2vec[1:]\n",
    "    \n",
    "def generator(train_samples, batch_size=32):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. Reads the image\n",
    "    2. Reads the question and appends the word2vec for the sentence. \n",
    "    3. Reads the answer and the options and appends the word2vec to the corresponding lists. \n",
    "    4. Have to tokenize the question and answer here. \n",
    "    \n",
    "    May need preprocessing of the question here. Get word 2 vecs of the word here. \n",
    "    The shape of the questions, answers, options1 to options3 is (N, T, D)\n",
    "    \n",
    "        N - number of samples\n",
    "        T - time steps in the RNN\n",
    "        D - dimension of the word 2 vector\n",
    "        \n",
    "    Returns: 1. Images batch, \n",
    "             2. Questions batch ,\n",
    "             3. Answers batch, \n",
    "             4. option1 batch, \n",
    "             5. option2 batch, \n",
    "             6. option3 batch\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = len(train_samples)\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        sklearn.utils.shuffle(train_samples)\n",
    "        \n",
    "        path_to_images = \"images/\"\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = train_samples[offset:offset+batch_size]\n",
    "            \n",
    "            train_images = []\n",
    "            questions = []\n",
    "            answers = []\n",
    "            options1 = []\n",
    "            options2 = []\n",
    "            options3 = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                image_path = batch_sample[0]\n",
    "                question   = batch_sample[1]\n",
    "                answer     = batch_sample[2]\n",
    "                choice1    = batch_sample[3]\n",
    "                choice2    = batch_sample[4]\n",
    "                choice3    = batch_sample[5]\n",
    "                \n",
    "                image1 = cv2.imread( path_to_images + batch_sample[0] )\n",
    "                image1 = cv2.resize(image1, (448,448))\n",
    "                train_images.append(image1)\n",
    "                \n",
    "                questions.append(vectorize(question, max_words = MAX_QUESTION_WORDS))\n",
    "                \n",
    "                answers.append(vectorize(answer, max_words = MAX_ANSWER_WORDS))\n",
    "                options1.append(vectorize(choice1, max_words = MAX_ANSWER_WORDS))\n",
    "                options2.append(vectorize(choice2, max_words = MAX_ANSWER_WORDS))\n",
    "                options3.append(vectorize(choice3, max_words = MAX_ANSWER_WORDS))\n",
    "                \n",
    "            \n",
    "            train_images = np.array(train_images)\n",
    "            questions = np.array(questions)\n",
    "            answers = np.array(answers)\n",
    "            options1 = np.array(options1)\n",
    "            options2 = np.array(options2)\n",
    "            options3 = np.array(options3)\n",
    "            \n",
    "            labels = np.zeros([batch_size,4])\n",
    "            labels[:,0] = 1\n",
    "            yield train_images, questions, answers, options1, options2, options3, labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels_placeholder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Considering that the score is the final logit value without the softmax. \n",
    "    \"\"\"\n",
    "#     print (\"score_value is: \", score)\n",
    "    final_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels_placeholder, dim = -1))\n",
    "    return final_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights path is:  ../weights/vgg16_weights.npz\n",
      "The weights are trainable\n",
      "weight_file is:  weights/vgg16_weights.npz\n"
     ]
    }
   ],
   "source": [
    "## 1\n",
    "cfg = Config()\n",
    "inputIm_placeholder, question_placeholder, answer_placeholder, \\\n",
    "option1_placeholder, option2_placeholder, option3_placeholder, labels_placeholder = load_placeholders(cfg)\n",
    "\n",
    "## 2. \n",
    "encode_image = encodeImage(cfg)\n",
    "## 3. \n",
    "sess = tf.Session()\n",
    "print (\"Weights path is: \",cfg.weights_path)\n",
    "\n",
    "## 4. \n",
    "with sess.as_default():\n",
    "    encode_image.load_weights(cfg.weights_path, sess, is_Train = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of final_conv_layer is:  (?, 8, 8, 512)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Loading Placeholders for the computational graph\n",
    "2. Creating object for the encoding image and encoding text\n",
    "3. Creating default session in tensorflow\n",
    "4. As the CNN model is pre trained, the loads are loaded in the encoder object within the defautl session. \n",
    "5. The computational graph is run for the convolution part. \n",
    "6. Encoding the question using the computational graph. \n",
    "7. \n",
    "\"\"\"\n",
    "\n",
    "## 5. \n",
    "final_conv_layer = encode_image.forward_pass(inputIm_placeholder)\n",
    "print (\"the shape of final_conv_layer is: \",final_conv_layer.get_shape())\n",
    "\n",
    "## Need to flatten the image here. \n",
    "final_conv_layer = tf.contrib.layers.flatten(final_conv_layer)\n",
    "print (\"final_conv_layer shape is: \", final_conv_layer.get_shape())\n",
    "\n",
    "fully_connected_object = fullyConnected(cfg)\n",
    "output_fully_connected = fully_connected_object.forward_pass(final_conv_layer)\n",
    "\n",
    "init_state = tf.Variable(tf.zeros([cfg.batch_size, cfg.state_size], dtype = tf.float32))\n",
    "\n",
    "## 6. \n",
    "with tf.variable_scope( \"question\", reuse = tf.AUTO_REUSE):\n",
    "    \"\"\"\n",
    "    Reuse permission is given to all the variables within this module. \n",
    "    \"\"\"\n",
    "    encode_text = encodeText(cfg)\n",
    "    output_fw_q, final_state_fw_q = encode_text.encode( question_placeholder, encoder_input = init_state) \n",
    "    \n",
    "with tf.variable_scope(\"answers\", reuse = tf.AUTO_REUSE):\n",
    "    \"\"\"\n",
    "    Reuse Permission is given to the answer as well.\n",
    "    \"\"\"\n",
    "    encode_answer = encodeText(cfg)\n",
    "    output_fw_a, final_state_fw_a       = encode_answer.encode(answer_placeholder,  final_state_fw_q)\n",
    "    output_fw_opt1, final_state_fw_opt1 = encode_answer.encode(option1_placeholder, final_state_fw_q)\n",
    "    output_fw_opt2, final_state_fw_opt2 = encode_answer.encode(option2_placeholder, final_state_fw_q)\n",
    "    output_fw_opt3, final_state_fw_opt3 = encode_answer.encode(option3_placeholder, final_state_fw_q)\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "Now I have to do the dot product of the two outputs and then send it to the loss function. \n",
    "\"\"\"\n",
    "pro_value1 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_a), axis = 1)\n",
    "pro_value2 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_opt1), axis = 1)\n",
    "pro_value3 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_opt2), axis = 1)\n",
    "pro_value4 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_opt3), axis = 1)\n",
    "\n",
    "print (\"pro_value1 shape is: \",pro_value1.get_shape())\n",
    "\n",
    "pro_value = tf.stack([pro_value1, pro_value2, pro_value3, pro_value4],axis =1 )\n",
    "print(\"pro_value shape is: \",pro_value.get_shape())\n",
    "loss = compute_loss(pro_value, labels_placeholder)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = 3e-4).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the Classifier. \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "savefile = \"models/model1.ckpt\"\n",
    "\n",
    "with sess.as_default():\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(cfg.num_epochs):\n",
    "        \n",
    "        print (\"Epoch Number: \",i)\n",
    "        batch_generator = generator(train_samples, cfg.batch_size)\n",
    "        total_iterations = int(len(train_samples)/cfg.batch_size)\n",
    "        \n",
    "        for j in range(total_iterations):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            batch_images_gen, batch_questions_gen, batch_answers_gen, batch_o1, batch_o2, batch_o3, labels = batch_generator.__next__()\n",
    "            \n",
    "            sess.run( train_step, feed_dict = \\\n",
    "                     {inputIm_placeholder: batch_images_gen, \\\n",
    "                      question_placeholder: batch_questions_gen,\\\n",
    "                      answer_placeholder: batch_answers_gen,\\\n",
    "                      option1_placeholder: batch_o1,\\\n",
    "                      option2_placeholder: batch_o2,\\\n",
    "                      option3_placeholder: batch_o3,\\\n",
    "                      labels_placeholder: labels\n",
    "                     })\n",
    "            \n",
    "            if(j%50==0):\n",
    "                loss_value= sess.run(loss, feed_dict = \\\n",
    "                     {inputIm_placeholder: batch_images_gen, \\\n",
    "                      question_placeholder: batch_questions_gen,\\\n",
    "                      answer_placeholder: batch_answers_gen,\\\n",
    "                      option1_placeholder: batch_o1,\\\n",
    "                      option2_placeholder: batch_o2,\\\n",
    "                      option3_placeholder: batch_o3,\\\n",
    "                      labels_placeholder: labels\n",
    "                     })\n",
    "                end_time = time.time()\n",
    "                print (\"Iter: \",j,' Total iter: ',total_iterations,\"Loss value is: \",loss_value, \" Time taken: \", end_time - start_time)\n",
    "                \n",
    "    saver.save(sess, savefile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
