{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Quesiton and Answering\n",
    "\n",
    "This notebook is about Visual Question and answering. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import cv2\n",
    "import csv\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from helpers.config import *\n",
    "from helpers.preprocessing import *\n",
    "from helpers.utils_v2 import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resetting default tensorflow computational Graph\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights file is :  ../weights/vgg16_weights.npz\n",
      "Config data path is:  ../data/dataset_v7w_telling.json\n",
      "Glove vectors path is:  ../data/glove.6B.50d.txt\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "print (\"Weights file is : \", cfg.weights_path)\n",
    "print (\"Config data path is: \",cfg.data_path)\n",
    "print (\"Glove vectors path is: \",cfg.glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data required for the Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of training samples are:  111894\n",
      "Validation examples number:  27974\n"
     ]
    }
   ],
   "source": [
    "samples = loadData(cfg.data_path.split('../')[1])\n",
    "train_samples, val_samples = train_test_split( samples, test_size= 0.2)\n",
    "print (\"Total number of training samples are: \",len(train_samples))\n",
    "print (\"Validation examples number: \",len(val_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Loading the Glove vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/glove.6B.50d.txt\n"
     ]
    }
   ],
   "source": [
    "## Loading glove vectors here. \n",
    "W2VEC = load_glove(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions available in the utils.py\n",
    "\n",
    "1. Encoding the image\n",
    "2. Encoding the text\n",
    "3. Loading the Weights of the pretrained model\n",
    "4. Loading placeholders\n",
    "5. Variables class\n",
    "6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "1. Load the image, question and answer here and train the network. \n",
    "2. Will get the output data in the shape (N, image, question, answer, groundtruth, option1, option2, option3)\n",
    "3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2VEC_LEN = 50\n",
    "def vectorize(sent, fill=15, clean=False):\n",
    "    \n",
    "    'Takes a sentence and returns corresponing list of GloVecs'\n",
    "    \n",
    "    if clean:\n",
    "        sent = _dataCleaning(sent)\n",
    "        \n",
    "    words = sent.split(\" \")\n",
    "    words = words[:fill]  #Capping the context. Beware!!\n",
    "    vecs = np.empty((1,W2VEC_LEN))\n",
    "    \n",
    "    for w in words:\n",
    "        vec = W2VEC.get(w.lower(), None)\n",
    "        if vec is None:\n",
    "            vec = np.random.rand(W2VEC_LEN)\n",
    "        vec = vec.reshape((1,W2VEC_LEN))\n",
    "        vecs = np.concatenate((vecs, vec), axis=0)\n",
    "    \n",
    "    PADDING = np.zeros((1, W2VEC_LEN))\n",
    "    \n",
    "    for _ in np.arange(fill - len(words)):\n",
    "        vecs = np.concatenate((vecs, PADDING), axis=0)\n",
    "    return vecs[1:]\n",
    "    \n",
    "def generator(train_samples, batch_size=32):\n",
    "    \n",
    "    \"\"\"\n",
    "    1. Reads the image\n",
    "    2. Reads the question and appends the word2vec for the sentence. \n",
    "    3. Reads the answer and the options and appends the word2vec to the corresponding lists. \n",
    "    4. Have to tokenize the question and answer here. \n",
    "    \n",
    "    May need preprocessing of the question here. Get word 2 vecs of the word here. \n",
    "    The shape of the questions, answers, options1 to options3 is (N, T, D)\n",
    "    \n",
    "        N - number of samples\n",
    "        T - time steps in the RNN\n",
    "        D - dimension of the word 2 vector\n",
    "        \n",
    "    Returns: 1. Images batch, \n",
    "             2. Questions batch ,\n",
    "             3. Answers batch, \n",
    "             4. option1 batch, \n",
    "             5. option2 batch, \n",
    "             6. option3 batch, \n",
    "             7. option4 batch\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = len(train_samples)\n",
    "    \n",
    "    while 1:\n",
    "        \n",
    "        sklearn.utils.shuffle(train_samples)\n",
    "        \n",
    "        path_to_images = \"images/\"\n",
    "        \n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = train_samples[offset:offset+batch_size]\n",
    "            \n",
    "            train_images = []\n",
    "            questions = []\n",
    "            answers = []\n",
    "            options1 = []\n",
    "            options2 = []\n",
    "            options3 = []\n",
    "#             options4 = []\n",
    "            \n",
    "            for batch_sample in batch_samples:\n",
    "                \n",
    "                image_path = batch_sample[0]\n",
    "                question   = batch_sample[1]\n",
    "                answer     = batch_sample[2]\n",
    "                choice1    = batch_sample[3]\n",
    "                choice2    = batch_sample[4]\n",
    "                choice3    = batch_sample[5]\n",
    "#                 choice4    = batch_sample[6]\n",
    "                \n",
    "                image1 = cv2.imread( path_to_images + batch_sample[0] )\n",
    "                image1 = cv2.resize(image1, (448,448))\n",
    "                train_images.append(image1)\n",
    "                \n",
    "                questions.append(vectorize(question, fill = 15))\n",
    "                \n",
    "                answers.append(vectorize(answer, fill = 5))\n",
    "                options1.append(vectorize(choice1, fill = 5))\n",
    "                options2.append(vectorize(choice2, fill = 5))\n",
    "                options3.append(vectorize(choice3, fill = 5))\n",
    "#                 options4.append(vectorize(answer))\n",
    "                \n",
    "            \n",
    "            train_images = np.array(train_images)\n",
    "            questions = np.array(questions)\n",
    "            answers = np.array(answers)\n",
    "            \n",
    "            options1 = np.array(options1)\n",
    "            options2 = np.array(options2)\n",
    "            options3 = np.array(options3)\n",
    "#             options4 = np.array(options4)\n",
    "            labels = np.zeros([batch_size,4])\n",
    "            labels[:,0] = 1\n",
    "            yield train_images, questions, answers, options1, options2, options3, labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(logits, labels_placeholder):\n",
    "    \n",
    "    \"\"\"\n",
    "    Considering that the score is the final logit value without the softmax. \n",
    "    \"\"\"\n",
    "#     print (\"score_value is: \", score)\n",
    "    final_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels_placeholder, dim = -1))\n",
    "    return final_loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the computational Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights path is:  ../weights/vgg16_weights.npz\n",
      "The weights are trainable\n",
      "weight_file is:  weights/vgg16_weights.npz\n"
     ]
    }
   ],
   "source": [
    "## 1\n",
    "cfg = Config()\n",
    "inputIm_placeholder, question_placeholder, answer_placeholder, \\\n",
    "option1_placeholder, option2_placeholder, option3_placeholder, labels_placeholder = load_placeholders(cfg)\n",
    "\n",
    "## 2. \n",
    "encode_image = encodeImage(cfg)\n",
    "## 3. \n",
    "sess = tf.Session()\n",
    "print (\"Weights path is: \",cfg.weights_path)\n",
    "\n",
    "## 4. \n",
    "with sess.as_default():\n",
    "    encode_image.load_weights(cfg.weights_path, sess, is_Train = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of final_conv_layer is:  (?, 8, 8, 512)\n",
      "final_conv_layer shape is:  (?, 32768)\n",
      "pro_value1 shape is:  (64,)\n",
      "pro_value shape is:  (64, 4)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "1. Loading Placeholders for the computational graph\n",
    "2. Creating object for the encoding image and encoding text\n",
    "3. Creating default session in tensorflow\n",
    "4. As the CNN model is pre trained, the loads are loaded in the encoder object within the defautl session. \n",
    "5. The computational graph is run for the convolution part. \n",
    "6. Encoding the question using the computational graph. \n",
    "7. \n",
    "\"\"\"\n",
    "\n",
    "## 5. \n",
    "final_conv_layer = encode_image.forward_pass(inputIm_placeholder)\n",
    "print (\"the shape of final_conv_layer is: \",final_conv_layer.get_shape())\n",
    "\n",
    "## Need to flatten the image here. \n",
    "final_conv_layer = tf.contrib.layers.flatten(final_conv_layer)\n",
    "print (\"final_conv_layer shape is: \", final_conv_layer.get_shape())\n",
    "\n",
    "fully_connected_object = fullyConnected(cfg)\n",
    "output_fully_connected = fully_connected_object.forward_pass(final_conv_layer)\n",
    "\n",
    "init_state = tf.Variable(tf.zeros([cfg.batch_size, cfg.state_size], dtype = tf.float32))\n",
    "\n",
    "## 6. \n",
    "with tf.variable_scope( \"question\", reuse = tf.AUTO_REUSE):\n",
    "    \"\"\"\n",
    "    Reuse permission is given to all the variables within this module. \n",
    "    \"\"\"\n",
    "    encode_text = encodeText(cfg)\n",
    "    output_fw_q, final_state_fw_q = encode_text.encode( question_placeholder, encoder_input = init_state) \n",
    "    \n",
    "with tf.variable_scope(\"answers\", reuse = tf.AUTO_REUSE):\n",
    "    \"\"\"\n",
    "    Reuse Permission is given to the answer as well.\n",
    "    \"\"\"\n",
    "    encode_answer = encodeText(cfg)\n",
    "    output_fw_a, final_state_fw_a       = encode_answer.encode(answer_placeholder,  final_state_fw_q)\n",
    "    output_fw_opt1, final_state_fw_opt1 = encode_answer.encode(option1_placeholder, final_state_fw_q)\n",
    "    output_fw_opt2, final_state_fw_opt2 = encode_answer.encode(option2_placeholder, final_state_fw_q)\n",
    "    output_fw_opt3, final_state_fw_opt3 = encode_answer.encode(option3_placeholder, final_state_fw_q)\n",
    "   \n",
    "\n",
    "\"\"\"\n",
    "Now I have to do the dot product of the two outputs and then send it to the loss function. \n",
    "\"\"\"\n",
    "pro_value1 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_a), axis = 1)\n",
    "pro_value2 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_opt1), axis = 1)\n",
    "pro_value3 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_opt2), axis = 1)\n",
    "pro_value4 = tf.reduce_sum(tf.multiply(final_state_fw_q, final_state_fw_opt3), axis = 1)\n",
    "\n",
    "print (\"pro_value1 shape is: \",pro_value1.get_shape())\n",
    "\n",
    "pro_value = tf.stack([pro_value1, pro_value2, pro_value3, pro_value4],axis =1 )\n",
    "print(\"pro_value shape is: \",pro_value.get_shape())\n",
    "loss = compute_loss(pro_value, labels_placeholder)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = 3e-4).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number:  0\n",
      "Iter:  0  Total iter:  1748 Loss value is:  87.5909  Time taken:  2.2883059978485107\n",
      "Iter:  50  Total iter:  1748 Loss value is:  84.4624  Time taken:  1.6613011360168457\n",
      "Iter:  100  Total iter:  1748 Loss value is:  87.5608  Time taken:  1.7637476921081543\n",
      "Iter:  150  Total iter:  1748 Loss value is:  87.6846  Time taken:  1.7257449626922607\n",
      "Iter:  200  Total iter:  1748 Loss value is:  81.1238  Time taken:  1.7341511249542236\n",
      "Iter:  250  Total iter:  1748 Loss value is:  84.7803  Time taken:  1.6020259857177734\n",
      "Iter:  300  Total iter:  1748 Loss value is:  83.1164  Time taken:  2.1360180377960205\n",
      "Iter:  350  Total iter:  1748 Loss value is:  88.4717  Time taken:  1.8142869472503662\n",
      "Iter:  400  Total iter:  1748 Loss value is:  89.3811  Time taken:  1.949051856994629\n",
      "Iter:  450  Total iter:  1748 Loss value is:  83.7706  Time taken:  1.6351568698883057\n",
      "Iter:  500  Total iter:  1748 Loss value is:  81.3424  Time taken:  1.5828630924224854\n",
      "Iter:  550  Total iter:  1748 Loss value is:  81.6601  Time taken:  1.6786580085754395\n",
      "Iter:  600  Total iter:  1748 Loss value is:  86.3152  Time taken:  1.574293851852417\n",
      "Iter:  650  Total iter:  1748 Loss value is:  85.5782  Time taken:  1.5449469089508057\n",
      "Iter:  700  Total iter:  1748 Loss value is:  81.0847  Time taken:  1.6532177925109863\n",
      "Iter:  750  Total iter:  1748 Loss value is:  85.6624  Time taken:  1.5947911739349365\n",
      "Iter:  800  Total iter:  1748 Loss value is:  84.3501  Time taken:  1.8748211860656738\n",
      "Iter:  850  Total iter:  1748 Loss value is:  84.419  Time taken:  1.6840581893920898\n",
      "Iter:  900  Total iter:  1748 Loss value is:  86.7368  Time taken:  1.629875898361206\n",
      "Iter:  950  Total iter:  1748 Loss value is:  85.8402  Time taken:  1.622920036315918\n",
      "Iter:  1000  Total iter:  1748 Loss value is:  88.2173  Time taken:  1.7218129634857178\n",
      "Iter:  1050  Total iter:  1748 Loss value is:  88.9877  Time taken:  1.5345358848571777\n",
      "Iter:  1100  Total iter:  1748 Loss value is:  84.6819  Time taken:  3.6937081813812256\n",
      "Iter:  1150  Total iter:  1748 Loss value is:  84.1621  Time taken:  3.615985870361328\n",
      "Iter:  1200  Total iter:  1748 Loss value is:  83.7452  Time taken:  1.6862449645996094\n",
      "Iter:  1250  Total iter:  1748 Loss value is:  81.3419  Time taken:  1.7015280723571777\n",
      "Iter:  1300  Total iter:  1748 Loss value is:  87.8213  Time taken:  1.5575480461120605\n",
      "Iter:  1350  Total iter:  1748 Loss value is:  79.4649  Time taken:  1.7286932468414307\n",
      "Iter:  1400  Total iter:  1748 Loss value is:  88.7468  Time taken:  1.599095106124878\n",
      "Iter:  1450  Total iter:  1748 Loss value is:  78.4616  Time taken:  1.7729759216308594\n",
      "Iter:  1500  Total iter:  1748 Loss value is:  82.642  Time taken:  1.7493970394134521\n",
      "Iter:  1550  Total iter:  1748 Loss value is:  84.2785  Time taken:  1.9333088397979736\n",
      "Iter:  1600  Total iter:  1748 Loss value is:  85.3463  Time taken:  1.7573440074920654\n",
      "Iter:  1650  Total iter:  1748 Loss value is:  87.4766  Time taken:  1.6999621391296387\n",
      "Iter:  1700  Total iter:  1748 Loss value is:  83.8335  Time taken:  1.582392692565918\n",
      "Epoch Number:  1\n",
      "Iter:  0  Total iter:  1748 Loss value is:  84.868  Time taken:  1.6318168640136719\n",
      "Iter:  50  Total iter:  1748 Loss value is:  83.9608  Time taken:  1.6916120052337646\n",
      "Iter:  100  Total iter:  1748 Loss value is:  84.1997  Time taken:  1.7421658039093018\n",
      "Iter:  150  Total iter:  1748 Loss value is:  79.4322  Time taken:  1.7090930938720703\n",
      "Iter:  200  Total iter:  1748 Loss value is:  74.608  Time taken:  1.7351009845733643\n",
      "Iter:  250  Total iter:  1748 Loss value is:  80.2975  Time taken:  1.6686859130859375\n",
      "Iter:  300  Total iter:  1748 Loss value is:  81.5161  Time taken:  1.6318070888519287\n",
      "Iter:  350  Total iter:  1748 Loss value is:  83.8605  Time taken:  1.719369888305664\n",
      "Iter:  400  Total iter:  1748 Loss value is:  83.1787  Time taken:  1.8792130947113037\n",
      "Iter:  450  Total iter:  1748 Loss value is:  82.3283  Time taken:  1.6493330001831055\n",
      "Iter:  500  Total iter:  1748 Loss value is:  79.7406  Time taken:  1.6134998798370361\n",
      "Iter:  550  Total iter:  1748 Loss value is:  78.6583  Time taken:  1.7228081226348877\n",
      "Iter:  600  Total iter:  1748 Loss value is:  84.6419  Time taken:  1.624298095703125\n"
     ]
    }
   ],
   "source": [
    "## Define the Classifier. \n",
    "\n",
    "saver = tf.train.Saver()\n",
    "savefile = \"models/model1.ckpt\"\n",
    "\n",
    "with sess.as_default():\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(cfg.num_epochs):\n",
    "        \n",
    "        print (\"Epoch Number: \",i)\n",
    "        batch_generator = generator(train_samples, cfg.batch_size)\n",
    "        total_iterations = int(len(train_samples)/cfg.batch_size)\n",
    "        \n",
    "        for j in range(total_iterations):\n",
    "            \n",
    "            start_time = time.time()\n",
    "            batch_images_gen, batch_questions_gen, batch_answers_gen, batch_o1, batch_o2, batch_o3, labels = batch_generator.__next__()\n",
    "            \n",
    "            sess.run( train_step, feed_dict = \\\n",
    "                     {inputIm_placeholder: batch_images_gen, \\\n",
    "                      question_placeholder: batch_questions_gen,\\\n",
    "                      answer_placeholder: batch_answers_gen,\\\n",
    "                      option1_placeholder: batch_o1,\\\n",
    "                      option2_placeholder: batch_o2,\\\n",
    "                      option3_placeholder: batch_o3,\\\n",
    "                      labels_placeholder: labels\n",
    "                     })\n",
    "            \n",
    "            if(j%50==0):\n",
    "                loss_value= sess.run(loss, feed_dict = \\\n",
    "                     {inputIm_placeholder: batch_images_gen, \\\n",
    "                      question_placeholder: batch_questions_gen,\\\n",
    "                      answer_placeholder: batch_answers_gen,\\\n",
    "                      option1_placeholder: batch_o1,\\\n",
    "                      option2_placeholder: batch_o2,\\\n",
    "                      option3_placeholder: batch_o3,\\\n",
    "                      labels_placeholder: labels\n",
    "                     })\n",
    "                end_time = time.time()\n",
    "                print (\"Iter: \",j,' Total iter: ',total_iterations,\"Loss value is: \",loss_value, \" Time taken: \", end_time - start_time)\n",
    "                \n",
    "    saver.save(sess, savefile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
